### Compressed Dialogue Models

---

Base chatbot was built with [DialoGPT Medium](https://www.microsoft.com/en-us/research/project/large-scale-pretraining-for-response-generation/) (with 345 million parameters)

---

With magnitude pruning we achieved a compressed chatbot model with only 30% of the parameters in DialoGPT-Medium with little degradation in engagingness.

---

Some modules in this repository were adapted from [HuggingFace Research](https://github.com/huggingface/transformers/tree/main/examples/research_projects)
